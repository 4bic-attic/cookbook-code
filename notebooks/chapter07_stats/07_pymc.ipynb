{
 "nbformat": 3, 
 "nbformat_minor": 0, 
 "worksheets": [
  {
   "cells": [
    {
     "source": [
      "> This is one of the 100 recipes of the [IPython Cookbook](http://ipython-books.github.io/), the definitive guide to high-performance scientific computing and data science in Python.\n"
     ], 
     "cell_type": "markdown", 
     "metadata": []
    }, 
    {
     "source": [
      "# 7.7. Fitting a Bayesian model by sampling from a posterior distribution with a Markov Chain Monte Carlo method"
     ], 
     "cell_type": "markdown", 
     "metadata": {
      "word_id": "4818_07_pymc"
     }
    }, 
    {
     "source": [
      "In this recipe, we illustrate a very common and useful method for characterizing a posterior distribution in a Bayesian model. Imagine you got some data and you want to obtain information about the underlying random phenomenon. In a frequentist approach, you could try to fit a probability distribution within a given family of distributions, using a parametric method like the maximum likelihood method. The optimization procedure would yield parameters that maximize the probability of observing the data given the null hypothesis.\n", 
      "\n", 
      "In a Bayesian approach, you consider the parameters themselves as random variables. Their prior distributions reflect your initial knowledge about those parameters. After the observations, your knowledge is updated: this is reflected in the posterior distributions of the parameters.\n", 
      "\n", 
      "A typical goal for Bayesian inference is to characterize the posterior distributions. Bayes' theorem gives an analytical way to do it, but it is often impractical in real-world problems due do the complexity of the models and the number of dimensions. A **Markov Chain Monte Carlo** method, like the **Metropolis-Hastings algorithm**, gives a numerical method to approximate a posterior distribution.\n", 
      "\n", 
      "Here, we introduce the *PyMC* package, which gives an effective and natural interface for fitting a probabilistic model to data in a Bayesian framework. We will look at the annual frequency of storms in the eastern Pacific Ocean since the 1950 using data from the NOAA."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "source": [
      "## Getting started\n", 
      "\n", 
      "You can find the instructions to install PyMC on the package's website. (http://pymc-devs.github.io/pymc/)\n", 
      "\n", 
      "You also need the *Storms* dataset from the book's website. (http://ipython-books.github.io)"
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "source": [
      "## How to do it..."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "source": [
      "1. Let's import the standard packages and PyMC."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "import numpy as np\n", 
      "import pandas as pd\n", 
      "import pymc\n", 
      "import matplotlib.pyplot as plt\n", 
      "%matplotlib inline"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "2. Let's import the data with Pandas."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "# http://www.ncdc.noaa.gov/ibtracs/index.php?name=wmo-data\n", 
      "df = pd.read_csv(\"data/Allstorms.ibtracs_wmo.v03r05.csv\",\n", 
      "                 delim_whitespace=False)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "3. With Pandas, it only takes a single line of code to get the annual number of storms in the North Atlantic Ocean. We first select the storms in that basin (`NA`), then we group the rows by year (`Season`), and we take the number of unique storm (`Serial_Num`) as each storm can span several days (`nunique` method)."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "cnt = df[df['Basin'] == ' NA'].groupby('Season') \\\n", 
      "      ['Serial_Num'].nunique()\n", 
      "years = cnt.index\n", 
      "y0, y1 = years[0], years[-1]\n", 
      "arr = cnt.values\n", 
      "plt.figure(figsize=(8,4));\n", 
      "plt.plot(years, arr, '-ok');\n", 
      "plt.xlim(y0, y1);\n", 
      "plt.xlabel(\"Year\");\n", 
      "plt.ylabel(\"Number of storms\");"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "4. Now, we define our probabilistic model. We assume that storms arise following a time-dependent Poisson process with a deterministic rate. We assume this rate is a piecewise-constant function that takes a first value `early_mean` before a certain switch point, and a second value `late_mean` after that point. These three unknown parameters are treated as random variables (we will describe them more in the *How it works...* section)."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "source": [
      "A [Poisson process](http://en.wikipedia.org/wiki/Poisson_process) is a particular **point process**, that is, a stochastic process describing the random occurence of instantaneous events. The Poisson process is fully random: the events occur independently at a given rate."
     ], 
     "cell_type": "markdown", 
     "metadata": {
      "style": "tip"
     }
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "switchpoint = pymc.DiscreteUniform('switchpoint',\n", 
      "                                   lower=0, upper=len(arr))\n", 
      "early_mean = pymc.Exponential('early_mean', beta=1)\n", 
      "late_mean = pymc.Exponential('late_mean', beta=1)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "5. We define the piecewise-constant rate as a Python function."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "@pymc.deterministic(plot=False)\n", 
      "def rate(s=switchpoint, e=early_mean, l=late_mean):\n", 
      "    out = np.empty(len(arr))\n", 
      "    out[:s] = e\n", 
      "    out[s:] = l\n", 
      "    return out"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "6. Finally, the observed variable is the annual number of storms. It follows a Poisson variable with a random mean (the rate of the underlying Poisson process). This fact is a known mathematical property of Poisson processes."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "storms = pymc.Poisson('storms', mu=rate, value=arr, observed=True)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "7. Now, we use the MCMC method to sample from the posterior distribution, given the observed data. The `sample` method launches the fitting iterative procedure."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "model = pymc.Model([switchpoint, early_mean, late_mean, rate, storms])"
     ], 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "mcmc = pymc.MCMC(model)\n", 
      "mcmc.sample(iter=10000, burn=1000, thin=10)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "8. Let's plot the sampled Markov chains. Their stationary distribution corresponds to the posterior distribution we want to characterize."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "plt.figure(figsize=(8,8))\n", 
      "plt.subplot(311);\n", 
      "plt.plot(mcmc.trace('switchpoint')[:]);\n", 
      "plt.ylabel(\"Switch point\"); \n", 
      "plt.subplot(312);\n", 
      "plt.plot(mcmc.trace('early_mean')[:]);\n", 
      "plt.ylabel(\"Early mean\");\n", 
      "plt.subplot(313);\n", 
      "plt.plot(mcmc.trace('late_mean')[:]);\n", 
      "plt.xlabel(\"Iteration\");\n", 
      "plt.ylabel(\"Late mean\");"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "9. We also plot the distribution of the samples: they correspond to the posterior distributions of our parameters, after the data points have been taken into account."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "plt.figure(figsize=(14,3))\n", 
      "plt.subplot(131);\n", 
      "plt.hist(mcmc.trace('switchpoint')[:] + y0, 15);\n", 
      "plt.xlabel(\"Switch point\")\n", 
      "plt.ylabel(\"Distribution\")\n", 
      "plt.subplot(132);\n", 
      "plt.hist(mcmc.trace('early_mean')[:], 15);\n", 
      "plt.xlabel(\"Early mean\");\n", 
      "plt.subplot(133);\n", 
      "plt.hist(mcmc.trace('late_mean')[:], 15);\n", 
      "plt.xlabel(\"Late mean\");"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "10. Taking the sample mean of these distributions, we get posterior estimates for the three unknown parameters, including the year where the frequency of storms suddenly increased."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "yp = y0 + mcmc.trace('switchpoint')[:].mean()\n", 
      "em = mcmc.trace('early_mean')[:].mean()\n", 
      "lm = mcmc.trace('late_mean')[:].mean()\n", 
      "print((yp, em, lm))"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "11. Now we can plot the estimated rate on top of the observations."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "plt.figure(figsize=(8,4));\n", 
      "plt.plot(years, arr, '-ok');\n", 
      "plt.axvline(yp, color='k', ls='--');\n", 
      "plt.plot([y0, yp], [em, em], '-b', lw=3);\n", 
      "plt.plot([yp, y1], [lm, lm], '-r', lw=3);\n", 
      "plt.xlim(y0, y1);\n", 
      "plt.xlabel(\"Year\");\n", 
      "plt.ylabel(\"Number of storms\");"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "For a possible scientific interpretation of the data considered here, see http://www.gfdl.noaa.gov/global-warming-and-hurricanes."
     ], 
     "cell_type": "markdown", 
     "metadata": {
      "style": "hidden"
     }
    }, 
    {
     "source": [
      "> You'll find all the explanations, figures, references, and much more in the book (to be released later this summer).\n\n> [IPython Cookbook](http://ipython-books.github.io/), by [Cyrille Rossant](http://cyrille.rossant.net), Packt Publishing, 2014 (400 pages). [Get a 50% discount by pre-ordering now](http://www.packtpub.com/ipython-interactive-computing-and-visualization-cookbook/book) with the code `PICVCEB` (time-limited offer)!\n"
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }
   ], 
   "metadata": {}
  }
 ], 
 "metadata": {
  "name": "", 
  "signature": "sha256:74afc120a8d4f0f0cb90d61f1c21031c75e0a09484f3de323ca37208806525ee"
 }
}