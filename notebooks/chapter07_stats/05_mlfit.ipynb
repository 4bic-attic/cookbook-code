{
 "nbformat": 3, 
 "nbformat_minor": 0, 
 "worksheets": [
  {
   "cells": [
    {
     "source": [
      "> This is one of the 100 recipes of the [IPython Cookbook](http://ipython-books.github.io/), the definitive guide to high-performance scientific computing and data science in Python.\n"
     ], 
     "cell_type": "markdown", 
     "metadata": []
    }, 
    {
     "source": [
      "# 7.5. Fitting a probability distribution to data with the maximum likelihood method\n", 
      "\n", 
      "A good way to explain a dataset is to apply a probabilistic model to it. Finding an adequate model can be a job in its own. Once a model is chosen, it is necessary to compare it to the data. This is what statistical estimation is about. In this recipe, we apply the **maximum likelihood method** on a dataset with survival times after heart transplant (1967-1974 study)."
     ], 
     "cell_type": "markdown", 
     "metadata": {
      "word_id": "4818_07_mlfit"
     }
    }, 
    {
     "source": [
      "## Getting started\n", 
      "\n", 
      "As usual in this chapter, a background in probability theory and real analysis is recommended. In addition, you need the statsmodels package to retrieve the test dataset. (http://statsmodels.sourceforge.net)"
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "source": [
      "## How to do it..."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "source": [
      "1. Statsmodels is a Python package for conducting statistical data analyses. It also contains real-world datasets that one can use when experimenting new methods. Here, we load the *heart* dataset."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "import numpy as np\n", 
      "import scipy.stats as st\n", 
      "import statsmodels.datasets\n", 
      "import matplotlib.pyplot as plt\n", 
      "%matplotlib inline"
     ], 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "data = statsmodels.datasets.heart.load_pandas().data"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "2. Let's take a look at this DataFrame."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "data.tail()"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "This dataset contains censored and uncensored data: a censor of 0 means that the patient was alive at the end of the study, so that we don't know the exact survival. We only know that the patient survived *at least* the indicated number of days. For simplicity here, we only keep uncensored data (we thereby create a bias toward patients that did not survive very long after their transplant...)."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "data = data[data.censors==1]\n", 
      "survival = data.survival"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "3. Let's take a look at the data graphically, by plotting the raw survival data and the histogram."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "plt.figure(figsize=(10,4));\n", 
      "plt.subplot(121);\n", 
      "plt.plot(sorted(survival)[::-1], 'o');\n", 
      "plt.xlabel('Patient');\n", 
      "plt.ylabel('Survival time (days)');\n", 
      "plt.subplot(122);\n", 
      "plt.hist(survival, bins=15);\n", 
      "plt.xlabel('Survival time (days)');\n", 
      "plt.ylabel('Number of patients');"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "4. We observe that the histogram is decreasing very rapidly. Fortunately, the survival rates are today much higher (~70% after 5 years). Let's try to fit an [exponential distribution](http://en.wikipedia.org/wiki/Exponential_distribution) to the data. According to this model, $S$ (number of days of survival) is an exponential random variable with parameter $\\lambda$, and the observations $s_i$ are sampled from this distribution. Let:\n", 
      "\n", 
      "$$\\overline s = \\frac 1 n \\sum s_i$$ \n", 
      "\n", 
      "be the sample mean. The likelihood function of an exponential distribution is, by definition (see proof in the next section):\n", 
      "\n", 
      "$$\\mathcal L(\\lambda, \\{s_i\\}) = P(\\{s_i\\} | \\lambda) = \\lambda^n \\exp\\left(-\\lambda n \\overline s\\right)$$\n", 
      "\n", 
      "The **maximum likelihood estimate** for the rate parameter is, by definition, the $\\lambda$ that maximizes the likelihood function. In other words, it is the parameter that maximizes the probability of observing the data, assuming that the observations are sampled from an exponential distribution.\n", 
      "\n", 
      "Here, it can be shown that the likelihood function has a maximum when $\\lambda = 1/\\overline s$, which is the *maximum likelihood estimate for the rate parameter*. Let's compute this parameter numerically."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "smean = survival.mean()\n", 
      "rate = 1./smean"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "5. To compare the fitted exponential distribution to the data, we first need to generate linearly spaced values for the x axis (days)."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "smax = survival.max()\n", 
      "days = np.linspace(0., smax, 1000)\n", 
      "dt = smax / 999.  # bin size: interval between two\n", 
      "                  # consecutive values in `days`"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "We can obtain the probability density function of the exponential distribution with SciPy. The parameter is the scale, the inverse of the estimated rate."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "dist_exp = st.expon.pdf(days, scale=1./rate)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "6. Now, let's plot the histogram and the obtained distribution. We need to rescale the theoretical distribution to the histogram (depending on the bin size and the total number of data points)."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "nbins = 30\n", 
      "plt.figure(figsize=(5,3));\n", 
      "plt.hist(survival, nbins);\n", 
      "plt.plot(days, dist_exp*len(survival)*smax/nbins,\n", 
      "         '-r', lw=3);"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "The fit is far from perfect... We were able to find an analytical formula for the maximum likelihood estimate here. In more complex situations, this is not always possible, so that one needs to resort to numerical methods. SciPy actually integrates numerical maximum likelihood routines for a large number of distributions. Here, we use this other method to estimate the parameter of the exponential distribution."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "dist = st.expon\n", 
      "args = dist.fit(survival); args"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "7. We can use these parameters to perform a **Kolmogorov-Smirnov test**, which assesses the goodness of fit of the distribution with respect to the data. This test is based on a distance between the **empirical distribution function** of the data and the **cumulative distribution function** (CDF) of the reference distribution."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "st.kstest(survival, dist.cdf, args)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "The second output value is the p-value. Here, it is very low: the null hypothesis (stating that the observed data stems from an exponential distribution with a maximum likelihood rate parameter) can be rejected with high confidence. Let's try another distribution, the *Birnbaum-Sanders distribution*, which is typically used to model failure times. (http://en.wikipedia.org/wiki/Birnbaum-Saunders_distribution)"
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "dist = st.fatiguelife\n", 
      "args = dist.fit(survival)\n", 
      "st.kstest(survival, dist.cdf, args)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "This time, the p-value is 0.07, so that we would not reject the null hypothesis with a 5% confidence level. When plotting the resulting distribution, we observe a better fit than with the exponential distribution."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "dist_fl = dist.pdf(days, *args)\n", 
      "nbins = 30\n", 
      "plt.figure(figsize=(5,3));\n", 
      "plt.hist(survival, nbins);\n", 
      "plt.plot(days, dist_exp*len(survival)*smax/nbins,\n", 
      "         '-r', lw=3, label='exp');\n", 
      "plt.plot(days, dist_fl*len(survival)*smax/nbins,\n", 
      "         '--g', lw=3, label='BS');\n", 
      "plt.xlabel(\"Survival time (days)\");\n", 
      "plt.ylabel(\"Number of patients\");\n", 
      "plt.legend();"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "> You'll find all the explanations, figures, references, and much more in the book (to be released later this summer).\n\n> [IPython Cookbook](http://ipython-books.github.io/), by [Cyrille Rossant](http://cyrille.rossant.net), Packt Publishing, 2014 (400 pages). [Get a 50% discount by pre-ordering now](http://www.packtpub.com/ipython-interactive-computing-and-visualization-cookbook/book) with the code `PICVCEB` (time-limited offer)!\n"
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }
   ], 
   "metadata": {}
  }
 ], 
 "metadata": {
  "name": "", 
  "signature": "sha256:54e6a7060088111b70086fad831ecaf4aeb2fc53cbcc066f7bdaff37478c2647"
 }
}