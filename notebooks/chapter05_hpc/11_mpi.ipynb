{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "word_id": "4818_05_mpi"
     },
     "source": [
      "# Using MPI with IPython\n",
      "\n",
      "**Message Passing Interface (MPI)** is a standardized communication protocol for parallel systems. It is used in many parallel computing applications to exchange data between nodes. MPI has a high barrier to entry, but it is very efficient and powerful.\n",
      "\n",
      "IPython's parallel computing system has been designed from the ground up to work with MPI. If you are new to MPI, it is a good idea to start using it with IPython. If you are an experienced MPI user, you will find that IPython integrates seamlessly with your parallel application.\n",
      "\n",
      "In this recipe, we show how to use MPI with IPython through a very simple example."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Getting started\n",
      "\n",
      "To use MPI with IPython you need:\n",
      "\n",
      "* A standard MPI implementation such as [OpenMPI](http://www.open-mpi.org) or [MPICH](http://www.mpich.org).\n",
      "* The [mpi4py package](http://mpi4py.scipy.org).\n",
      "\n",
      "For example, here are the commands to install MPI for IPython on Ubuntu:\n",
      "\n",
      "    > sudo apt-get install libcr-dev mpich2 mpich2-doc\n",
      "    > sudo apt-get install python-mpi4py\n",
      "    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How to do it..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. We first need to create a MPI profile with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ipython profile create --parallel --profile=mpi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2. Then, we need to open `~/.ipython/profile_mpi/ipcluster_config.py` and add the line `c.IPClusterEngines.engine_launcher_class = 'MPI'`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3. Once the MPI profile has been created and configured, we can launch the engines in the IPython dashboard, by selecting the number of engines (e.g. one per processor) in the *Clusters* tab, *MPI* profile, and pressing *Start*. Alternatively, we can run in a terminal: `ipcluster start -n 2 --engines MPI --profile=mpi`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "4. Now, to actually use the engines, we create a MPI client in the notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from IPython.parallel import Client"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = Client(profile='mpi')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "5. Let's create a view on all engines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "view = c[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "6. In this example, we compute the sum of all integers between 0 and 15 in parallel over two cores. We first distribute the array with the 16 values across the engines (each engine gets a subarray)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "view.scatter('a', np.arange(16., dtype='float'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<AsyncResult: scatter>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "7. We compute the total sum in parallel using MPI's `allreduce` function. Every node makes the same computation and returns the same result."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from mpi4py import MPI\n",
      "import numpy as np\n",
      "print MPI.COMM_WORLD.allreduce(np.sum(a), op=MPI.SUM)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] 120.0\n",
        "[stdout:1] 120.0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How it works...\n",
      "\n",
      "In this example, each node:\n",
      "\n",
      "1. receives a subset of the integers,\n",
      "2. computes the local sum of those integers,\n",
      "3. sends this local sum to all other engines,\n",
      "4. receives the local sum of the other engines,\n",
      "5. computes the total sum of those local sums.\n",
      "\n",
      "This is how **all-reduce** works in MPI: the principle is to **scatter** data across engines first, then to **reduce** the local computations through a global operator (here, `MPI.SUM`).\n",
      "\n",
      "There are many other parallel computing paradigms in MPI. You can find more information here:\n",
      "\n",
      "* [MPI tutorials by Wes Kendall](http://mpitutorial.com)\n",
      "* [MPI tutorials by Blaise Barney, Lawrence Livermore National Laboratory](https://computing.llnl.gov/tutorials/mpi/)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## See also\n",
      "\n",
      "* Distribute your code across multiple cores with IPython"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}